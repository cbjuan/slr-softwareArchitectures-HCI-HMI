"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&rowsPerPage%3D75%26queryText%3D%28%22software+architectur*%22+AND+%28%28HCI+OR+%22Human-Computer+Interaction%22+OR+%22Human+Computer+Interaction%22%29+OR+%28HMI+OR+%22Human-Machine+Interaction%22+OR+%22Human+Machine+Interaction%22%29%29%29",2017/05/04 16:53:42
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Speech based human machine interaction system for home automation","M. Katore; M. R. Bachute","Department of E & Tc., G.H. Raisoni Institute of Engineering & Technology, Pune, India","2015 IEEE Bombay Section Symposium (IBSS)","20160421","2015","","","1","6","Human-machine interaction technology defines the way human use machines and it plays crucial role for developing an ecosystem between user and machine. Speech based Human-machine interaction has potential to be future of Human-machine interaction and recent advancement in technology have made it possible to operate computers and electronic devices through speech. While there are lots of research going on for the development of better speech recognition systems but very less efforts are made to develop speech based Human-machine interaction system for everyday use. This paper presents an innovative approach by integrating an Android enabled device, Bluetooth technology, Matlab computing platform and advanced microcontroller to develop a Speech based Human-machine interaction system for operating home appliances. The proposed system is very effective speech based Human-machine interaction system for real world applications as it is affordable, flexible, user configurable, user friendly, and also it is very helpful for elderly persons and disabled people.","","Electronic:978-1-4673-9542-7; POD:978-1-4673-9543-4","10.1109/IBSS.2015.7456634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456634","Android application;Bluetooth technology;Human Machine Interaction (HMI)systems;Human-computer interaction (HCI) systems;Matlab;Microcontroller;Speech commands;Speech recognition","Androids;Bluetooth;Humanoid robots;MATLAB;Man machine systems;Speech;Speech recognition","Bluetooth;home automation;man-machine systems;mathematics computing;smart phones;speech recognition","Android enabled device;Bluetooth technology;Matlab computing platform;disabled people;elderly persons;electronic devices;home appliances;home automation;microcontroller;speech based human machine interaction system;speech based human-machine interaction;speech recognition systems","","","","19","","","10-11 Sept. 2015","","IEEE","IEEE Conference Publications"
"A review study of human-affection knowledge on usability engineering","D. Lakshmi; R. Ponnusamy","Dept. of Computer Science and Engineering, Satyabama University, Chennai, Tamilnadu, India","2016 International Conference on Advances in Human Machine Interaction (HMI)","20160409","2016","","","1","7","An increasingly large amount of multimodal content is posted on social media websites such as YouTube and Facebook every day. In order to cope with the growth of such so much multimodal data, there is very urgent need to develop an intelligent multi-modal analysis framework that can effectively extract information from multiple modalities. In this research work, here propose a novel multimodal information extraction agent, which infers and aggregates the semantic and affective information associated with user generated multimodal data in contexts such as e-learning, e-health, automatic video content tagging and human-computer interaction (HCI). In particular, the developed intelligent agent adopts an ensemble feature extraction approach by exploiting the joint use of tri-modal (text, audio and video data) features to enhance the multimodal information extraction process. In preliminary experiments using the INTERFACE and SEMINE dataset, our proposed multi-modal system is shown to achieve an accuracy of 88.75%, outperforming the best state-of-the-art system by more than 10%, or in relative terms, a 46% reduction in error rate.","","Electronic:978-1-4673-8810-8; POD:978-1-4673-8811-5","10.1109/HMI.2016.7449174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449174","Affection;HCI;Modalaties;Multi model Analysis;Video","Cameras;Computers;Electroencephalography;Feature extraction;Human computer interaction;Sensors;Three-dimensional displays","human computer interaction;social networking (online)","Facebook;HCI;YouTube;feature extraction approach;human-affection knowledge;human-computer interaction;intelligent multimodal analysis framework;multimodal information extraction agent;social media Web sites;usability engineering","","","","51","","","3-5 March 2016","","IEEE","IEEE Conference Publications"
"A statistical approach for estimating user satisfaction in spoken human-machine interaction","A. Schmitt; B. Schatz; W. Minker","Dialogue Systems Research Group, University of Ulm, Albert-Einstein-Allee 43, 89081 Ulm, Germany","2011 IEEE Jordan Conference on Applied Electrical Engineering and Computing Technologies (AEECT)","20120119","2011","","","1","6","This paper addresses a new approach for statistical modeling of user satisfaction in Spoken Dialogue Systems (SDS) and thereby allows an online monitoring of spoken human-machine interaction. The presented technique relies on a large set of input variables originating from system log files that quantify the ongoing spoken human-machine interaction. The target variable, user satisfaction (US), is captured in a lab study on a 5 point scale with 46 users interacting with an SDS. The model, which is based on Support Vector Machines (SVM) yields a performance of 49.2% unweighted average recall (Cohen's κ = .442, Spearman's ρ = .668) and significantly outperforms related work in that field.","","Electronic:978-1-4577-1084-1; POD:978-1-4577-1083-4","10.1109/AEECT.2011.6132535","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6132535","Artificial Intelligence;HCI;HMI;Human Computer Interaction;Machine Learning;Spoken Dialogue System;User Modeling","Computational modeling;Computers;Delta modulation;Electrical engineering;Input variables;Predictive models;Support vector machines","man-machine systems;statistical analysis;support vector machines;user interfaces","spoken dialogue systems;spoken human-machine interaction;statistical approach;support vector machines;user satisfaction","","1","","16","","","6-8 Dec. 2011","","IEEE","IEEE Conference Publications"
"A formal framework for design and analysis of human-machine interaction","S. Combéfis; D. Giannakopoulou; C. Pecheur; M. Feary","Computer Science and Engineering Department, ICT, Electronics and Applied Mathematics Institute, Universit&#x00E9; catholique de Louvain, Louvain-la-Neuve, Belgium","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","1801","1808","Automated systems are increasingly complex, making it hard to design interfaces for human operators. Human-machine interaction (HMI) errors like automation surprises are more likely to appear and lead to system failures or accidents. In previous work, we studied the problem of generating system abstractions, called mental models, that facilitate system understanding while allowing proper control of the system by operators as defined by the full-control property. Both the domain and its mental model have Labelled Transition Systems (LTS) semantics, and we proposed algorithms for automatically generating minimal mental models as well as checking full-control. This paper presents a methodology and an associated framework for using the above and other formal method based algorithms to support the design of HMI systems. The framework can be used for modelling HMI systems and analysing models against HMI vulnerabilities. The analysis can be used for validation purposes or for generating artifacts such as mental models, manuals and recovery procedures. The framework is implemented in the JavaPathfinder model checker. Our methodology is demonstrated on two examples, an existing benchmark of a medical device, and a model generated from the ADEPT toolset developed at NASA Ames. Guidelines about how ADEPT models can be translated automatically into JavaPathfinder models are also discussed.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6083933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083933","Formal methods;HCI;Learning","Algorithm design and analysis;Analytical models;Cognitive science;Decoding;Humans;Presses;Usability","formal verification;human computer interaction","ADEPT toolset;HMI;JavaPathfinder model checker;LTS semantics;formal framework;human-machine interaction;labelled transition system;mental model","","3","","28","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"User and Usability Modeling for HCI/HMI: A Research Design","S. Adikari; C. McDonald","School of Information Sciences and Engineering, University of Canberra, ACT 2601 Australia. Sisira.Adikari@canberra.edu.au","2006 International Conference on Information and Automation","20070625","2006","","","151","154","A key reason for the presence of poor usability in products is the insufficient specification of usability perspectives effectively in product requirements specifications. The explicit expression of usability perspective in product requirements specifications is quite important in providing a clear visibility of usability aspects for both product developers and testers. Such specifications incorporating usability of human-interactive systems can be built for optimal usability and also evaluated effectively to uncover usability related issues. In this paper, we present a design science-oriented research design to test the proposition that incorporating user modeling and usability modeling in product requirements specifications improves design. We expect our proposal and the research design will make a contribution to knowledge by theory testing and to practice with effective techniques to specify usable human-interactive systems.","2151-1802;21511802","CD-ROM:1-4244-0555-6; POD:1-4244-0554-8","10.1109/ICINFA.2006.374099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4250189","Human-Computer Interaction (HCI);Human-Machine Interaction (HMI);User modeling;usability modeling","Australia;Behavioral science;Context modeling;Design engineering;Human computer interaction;Information systems;Man machine systems;Process design;System testing;Usability","formal specification;human computer interaction;interactive systems;user interface management systems;user modelling","HCI;HMI;design science-oriented research;human computer interaction;human-interactive systems;human-machine interaction;product requirements specification;usability modeling;user modeling","","1","","25","","","15-17 Dec. 2006","","IEEE","IEEE Conference Publications"
"Smooth Path Planning for Intelligent Wheelchair Based on Human-Machine Interaction","T. Lu; K. Yuan; W. Zou; H. Hu","Hi-tech Innovation Center, Institute of Automation, CAS, Beijing, China, email: tlu@hitic.ia.ac.cn","2006 IEEE International Conference on Information Acquisition","20070212","2006","","","988","993","Path planning is a complicated and challenge problem in mobile robotics if a mobile robot is expected operated in the real world. Human-machine interaction (HMI) could play an important role in this process and the robot can get help from the user during path planning. In this paper, we introduce a smooth path planning method for an intelligent wheelchair (IW) based on HMI. The user first presents some key points on a known environment map to the system via HCI. Then these key points are used by IW as path skeleton points for generating a smooth collision-free path. Under the cooperation of the user and IW, smooth path planning becomes easy and convenient. Simulation results show that the proposed method works well and very convenient for the user","","CD-ROM:1-4244-0529-7; POD:1-4244-0528-9","10.1109/ICIA.2006.305872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4097805","Human-robot interaction;Intelligent wheelchair;Smooth path planning","Content addressable storage;Human computer interaction;Intelligent robots;Man machine systems;Medical services;Mobile robots;Path planning;Senior citizens;Technological innovation;Wheelchairs","handicapped aids;human computer interaction;intelligent robots;man-machine systems;medical robotics;mobile robots;path planning","HCI;human-machine interaction;intelligent wheelchair;mobile robotics;smooth path planning","","1","","18","","","20-23 Aug. 2006","","IEEE","IEEE Conference Publications"
"Notice of Violation of IEEE Publication Principles<BR>Advanced recognition techniques for human computer interaction","C. A. Burande; R. M. Tugnayat; N. K. Choudhary","Information Technology Dept., Jawaharlal Darda Institute of Engg & Tech, Yavatmal, India","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","2","","480","483","Notice of Violation of IEEE Publication Principles<BR><BR>""Advanced Recognition Techniques for Human Computer Interaction""<BR>by Chetan A. Burande, Raju M. Tugnayat, Nitin K. Choudhary<BR>in the Proceedings of the 2nd International Conference on Computer and Automation Engineering (ICCAE), February 2010, pp. 480-483<BR><BR>After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles. <BR><BR>This paper contains substantial duplication of text and figures from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.<BR><BR> Due to the nature of this violation, reasonable effort should be made to remove all past references to this paper, and future references should be made to the following article:<BR><BR>""Hand Gesture Recognition for Human-Machine Interaction""<BR>by Elena Sanchez-Nielsen (1), Luis Anton-Canalis (1), Mario Hernandez-Tejera (2)<BR>in the Journal of WSCG, Vol 12, No. I-3, February 2003, pp. 395-402<BR><BR>Hand gestures are an important modality for human computer interaction (HCI). Compared to many existing interfaces, hand gestures have the advantages of being easy to use, natural, and intuitive. Successful applications of hand gesture recognition include computer games control, human-robot interaction, and sign language recognition, to name a few. Vision-based recognition systems can give computers the capability of understanding and responding to hand gestures. The aim of this technique is the proposal of a real time vision system for its application within visual interaction environments through hand gesture recognition, using general-purpose hardware and low cost sensors, like a simple personal computer and an USB web cam, so any user could make use of it in his office or home. The basis of our- approach is a fast segmentation process to obtain the moving hand from the whole image, which is able to deal with a large number of hand shapes against different backgrounds and lighting conditions, and a recognition process that identifies the hand posture from the temporal sequence of segmented hands. The use of a visual memory (Stored database) allows the system to handle variations within a gesture and speed up the recognition process through the storage of different variables related to each gesture. A hierarchical gesture recognition algorithm is introduced to recognize a large number of gestures. Three stages of the proposed algorithm are based on a new hand tracking technique to recognize the actual beginning of a gesture using a Kalman filtering process, hidden Markov models and graph matching. Processing time is important in working with large databases. Therefore, special cares are taken to deal with the large number of gestures.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451617","","Application software;Computer vision;Costs;Handicapped aids;Hardware;Human computer interaction;Image segmentation;Machine vision;Proposals;Real time systems","Kalman filters;computer vision;database management systems;gesture recognition;graph theory;hidden Markov models;human computer interaction;image segmentation;optical tracking;real-time systems","Kalman filtering;USB Web cam;general-purpose hardware;graph matching;hand gesture recognition;hand shape;hand tracking;hidden Markov model;hierarchical gesture recognition;human computer interaction;low cost sensor;personal computer;real time vision system;segmentation process;stored database;vision-based recognition system;visual interaction environment;visual memory","","1","","14","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Collaborative Systems & Shared Economy (Uberization): Principles & Case Study","B. David; R. Chalon; C. Yin","LIRIS, Univ. de Lyon, Lyon, France","2016 International Conference on Collaboration Technologies and Systems (CTS)","20170306","2016","","","57","63","In this paper we analyze the characteristics of collaborative systems and the characteristics of shared economy supporting systems. Uberization as present in many applications: Airbnb, Uber, BlablaCar, AMAP, circular economy, etc. needs a cooperative system support. We examine this approach from the point of view of ICT (Information and Communication Technologies) and, more specifically, HMI (Human Machine Interaction) and CSCW (Computer Supported Cooperative Work) and indicate what must be added to collaborative systems to support uberization. This paper also shows how to identify appropriate collaborative models and how to add new uberization services to obtain an uberization supporting platform. A case of design of a collaborative application for Carbon Free Parcel Distribution is also presented, and corresponding intermediation algorithms are discussed.","","Electronic:978-1-5090-2300-4; POD:978-1-5090-2301-1","10.1109/CTS.2016.0029","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870967","Collaborative system;intermediation;platform;shared economy;uberization","Biological system modeling;Collaborative software;Collaborative work;Computer architecture;Organizations;Transportation","business data processing;groupware;human computer interaction","CSCW;HMI;ICT;carbon free parcel distribution;collaborative systems;computer supported cooperative work;human machine interaction;information and communication technologies;shared economy supporting systems;uberization","","","","","","","Oct. 31 2016-Nov. 4 2016","","IEEE","IEEE Conference Publications"
"Psychophysiologically Based Real-Time Adaptive General Type 2 Fuzzy Modeling and Self-Organizing Control of Operator's Performance Undertaking a Cognitive Task","L. A. Torres Salomao; M. Mahfouf; E. El-Samahy; C. H. Ting","Department of Automatic Control and Systems Engineering, The University of Sheffield, Sheffield, U.K.","IEEE Transactions on Fuzzy Systems","20170201","2017","25","1","43","57","This paper presents a new modeling and control fuzzy-based framework validated with real-time experiments on human participants experiencing stress via mental arithmetic cognitive tasks identified through psychophysiological markers. The ultimate aim of the modeling/control framework is to prevent performance breakdown in human-computer interactive systems with a special focus on human performance. Two designed modeling/control experiments which consist of carrying-out arithmetic operations of varying difficulty levels were performed by ten participants (operators) in the study. With this new technique, modeling is achieved through a new adaptive, self-organizing, and interpretable modeling framework based on general Type-2 fuzzy sets. This framework is able to learn in real time through the implementation of a restructured performance learning algorithm that identifies important features in the data without the need for prior training. The information learnt by the model is later exploited via an energy model based controller that infers adequate control actions by changing the difficulty level of the arithmetic operations in the human-computer interaction system; these actions being based on the most current psychophysiological state of the subject under study. The real-time implementation of the proposed modeling and control configurations for the human-machine interaction under study shows superior performance as compared to other forms of modeling and control, with minimal intervention in terms of model retraining or parameter retuning to deal with uncertainties, disturbances, and inter/intrasubject parameter variability.","1063-6706;10636706","","10.1109/TFUZZ.2016.2598363","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7534871","Adaptive;Type 2 fuzzy sets;control;human–machine interaction (HMI);mental stress;modeling;psychophysiological markers;real time","Adaptation models;Adaptive systems;Computational modeling;Real-time systems;Stress;Training","adaptive control;arithmetic;cognition;fuzzy control;fuzzy set theory;human computer interaction;learning systems;mathematical operators;psychology;real-time systems;self-adjusting systems","arithmetic operations;energy model based controller;fuzzy-based framework control;fuzzy-based framework modeling;human performance;human-computer interactive systems;mental arithmetic cognitive tasks;psychophysiological markers;psychophysiologically based real-time adaptive general type 2 fuzzy modeling;restructured performance learning algorithm;self-organizing control;self-organizing modeling;stress;type-2 fuzzy sets","","","","","","20160805","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"An Intelligent SPN Dialogue Model for Extracting Non-Measurable Pathological Symptoms","S. Mallios; N. Bourbakis","Center of Assistive Res. Technol., Wright State Univ., Dayton, OH, USA","2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)","20170116","2016","","","758","765","The increasing occurrence of chronic conditions among the ageing population and people at risk is one of the major challenges for our society and the high cost for its healthcare systems. Prevention, early detection and efficient management of chronic, long-term conditions contribute radically to the individual wellbeing and the economic sustainability of social and healthcare systems. In response to this need, this paper offers a human-machine interaction (HMI) model using Stochastic Petri Nets (SPNs). This HMI is based on a dialogue model between a virtual medical doctor and a patient for the efficient extraction of non-measurable pathological symptoms. Thus, the goal of such a model is the improvement of life critical situations and long delays (or appointments) for certain categories of people in need, like the elderly or people with disabilities.","","Electronic:978-1-5090-4459-7; POD:978-1-5090-4460-3","10.1109/ICTAI.2016.0119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814679","dialogue manager model;dialogue systems;health monitoring;human-machine interaction;stochastic Petri nets","Artificial intelligence;Conferences","Petri nets;geriatrics;handicapped aids;health care;human computer interaction;interactive systems;stochastic processes;telemedicine","HMI model;ageing population;chronic long-term conditions;early detection;economic sustainability;elderly people;healthcare systems;human-machine interaction model;individual wellbeing;intelligent SPN dialogue model;nonmeasurable pathological symptom extraction;people with disabilities;stochastic Petri nets;virtual medical doctor","","","","","","","6-8 Nov. 2016","","IEEE","IEEE Conference Publications"
"An image compression for embedded eye-tracking applications","P. Morozkin; M. Swynghedauw; M. Trocan","SuriCog, Paris, France","2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)","20160922","2016","","","1","5","Human-machine interaction is becoming a sufficient part of coming future. Being a bright example of HMI, embedded eye-tracking systems allow user to interact with objects by using human's eye-movements. Due to wearable form-factor, developed eye-tracking system has to conform to low-power consumption, low-heat generation and low EM radiation as well as support wireless data transmission and be space efficient. Image capturing, finding of region of interest (ROI), compression of ROI and wireless transmission of compressed data are very beginning steps of the whole algorithm of finding coordinates of pupil. Therefore, area of concentration is to make them as performant as possible from theoretical point of view to further implementation. Combination of hardware powered ROI-finder coupled with well-tuned and optimized image compression system is aimed to speed-up wireless delivery of ROI-images to processing unit. Details of design of such system are presented and discussed.","","","10.1109/INISTA.2016.7571852","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571852","FPGA;embedded eye-tracking;human-machine interaction;image compression;wireless data transmission","Bit rate;Codecs;Delays;Frequency-domain analysis;Image coding;Transform coding;Wireless sensor networks","gaze tracking;human computer interaction;image coding;object tracking","EM radiation;HMI;embedded eye-tracking;heat generation;human eye-movement;human-machine interaction;image capturing;image compression;power consumption;region-of-interest compression;wearable form-factor;wireless data transmission","","","","","","","2-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"Cortically Coupled Computing: A New Paradigm for Synergistic Human-Machine Interaction","S. Saproo; J. Faller; V. Shih; P. Sajda; N. R. Waytowich; A. Bohannon; V. J. Lawhern; B. J. Lance; D. Jangraw","Columbia University","Computer","20160907","2016","49","9","60","68","Unlike traditional brain-computer interfaces that use brain signals for direct control of computers and robotics, a cortically coupled computer system opportunistically senses the brain state, capturing a user's implicit or explicit computation, and then communicates this information to a traditional computer system via a neural interface.","0018-9162;00189162","","10.1109/MC.2016.294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562326","AI;BCI;C3V;CV;HMI;IEEE Brain Initiative;artificial intelligence;bioengineering;bioinformatics;brain-computer interface;computer vision;computing paradigms;cortically coupled computer vision;cortically coupled computing;data analysis;deep learning;human-autonomy integration;human-machine interaction;human-machine interface;intelligent systems;machine learning;neural computing;visualization","Artificial intelligence;Bioengineering;Computer vision;Coupled computing;Data analysis;Intelligent systems;Machine learning;Man-machine interfaces;Neural computing","brain-computer interfaces;human computer interaction","brain-computer interface;cortically coupled computing;neural interface;synergistic human-machine interaction","","","","","","","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"A framework for human-machine interaction using Depthmap and compactness","Jyothilakshmi P; K. R. Rekha; K. R. Nataraj","Jain University, Bengalore, India","2015 International Conference on Emerging Research in Electronics, Computer Science and Technology (ICERECT)","20160627","2015","","","462","467","In recent past research and development in the field of Human-computer/machine interaction (HMI) is on fast track because there has been enough advancement of technologies such as advanced image processing techniques and sensors etc. which provides ease to formulate a test bed to experiment various HMI. A device called Kinect has been introduced for controlling functionalities of windows operating system, which is being widely used in Xbox games by Microsoft. This paper illustrates one of the popular HMI application called mouse control using hand gesture recognition. The method is named as hand-mouse (HM). HM tracks the full body vital core point and the movement of palm controls the movement of mouse cursor and the opening and closing of palm controls a mouse click events. The HM system is using Kinect in order to avoid wearing of any sensors or gesture training dataset, which reduces the computational overhead and experimental results demonstrates a real time output with satisfactory results having higher true positive and lesser false negative.","","Electronic:978-1-4673-9563-2; POD:978-1-4673-9564-9","10.1109/ERECT.2015.7499060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7499060","Digital Image Processing;Hand Gesture;Human Machine Interface;Mouse Control","Cameras;Gesture recognition;Mathematical model;Mice;Sensors;Skeleton;Tracking","computer games;human computer interaction;image processing;man-machine systems;mouse controllers (computers);operating systems (computers)","HM system;HMI;Kinect;Microsoft;Xbox games;advanced image processing techniques;hand gesture recognition;hand-mouse;human-machine interaction;mouse click events;mouse control;windows operating system","","","","20","","","17-19 Dec. 2015","","IEEE","IEEE Conference Publications"
"A comparison of two takeoff and climb out flap retraction standard operating procedures","H. K. Kourdali; L. Sherry","Center for Air Transportation Systems Research (CATSR) at George Mason University (GMU), Fairfax, VA, USA","2016 Integrated Communications Navigation and Surveillance (ICNS)","20160609","2016","","","4A2-1","4A2-14","Takeoff and climb out flap retraction is a procedure that is conducted following takeoff to retract the flaps and slats from a takeoff configuration to a clean-up-and-away configuration. During this period the aircraft accelerates from the takeoff V2 speed to 250 knots and generally includes a thrust reduction from the takeoff thrust setting to the climb thrust setting. Timing of the flap retraction is critical to avoid overspeed or underspeed. Also, due to the vicinity of terrain and traffic, the aircraft performance and airspace must be carefully monitored while staying responsive to Air Traffic Control voice communication. As a result the design and certification of these procedures must resolve multiple conflicting objectives. This paper describes a formal analysis of alternate takeoff flap retraction procedures for the BAE 146 (Avro) aircraft. One procedure requires a “callout” by the Pilot Flying (PF) for each stage of flap retraction. The other procedure delegates flap retraction to the Pilot Monitoring (PM). A formal analysis of the procedures using the Human Machine Interaction Sequence Diagram (HMI-SD) method yielded equal utility. Overall, the Callout procedure is more robust to interruption and provides a better shared mental model between the crew members. However, the Delegate procedure can be completed on average 4.5 seconds faster providing more time for monitoring or performing other tasks. The implications and limitations of the formal procedure analysis is discussed.","","Electronic:978-1-5090-2149-9; POD:978-1-5090-2150-5","10.1109/ICNSURV.2016.7486344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486344","","Acceleration;Air traffic control;Aircraft;Cognitive science;Monitoring;Monte Carlo methods;Robustness","aerospace computing;air traffic control;human computer interaction","BAE 146 aircraft;HMI-SD method;PM;air traffic control voice communication;callout procedure;clean-up-and-away configuration;climb thrust setting;formal procedure analysis;human machine interaction sequence diagram method;pilot monitoring;takeoff and climb out flap retraction;takeoff thrust setting;thrust reduction","","","","6","","","19-21 April 2016","","IEEE","IEEE Conference Publications"
"SEMG based human computer interface for physically challenged patients","M. Shafivulla","Department of Electronics and Communication Engineering, KLU, Vijayawada-534007, A.P. India","2016 International Conference on Advances in Human Machine Interaction (HMI)","20160409","2016","","","1","4","This paper present the use of hand gestures for human-computer interaction, this paper presents an approach to identify hand gestures using muscle activity separated from electromyogram (EMG) using ANN. To retain a constraint-free user's environment, EMG sensing is limited to three arm muscles. EMG signals are processed to attain parameters that are related to the muscles temporal activities. The attainment of these parameters through time constructs a unique signature for each particular gesture. Experimental investigation was carried out to examine the system's reliability in recognizing 6 arm gestures. The results show that the system can recognize the 6 gestures with a success rate of 98%. The advantage of such a system is that it is easy to train by a layer, and can easily be implemented in real time after the initial training.","","Electronic:978-1-4673-8810-8; POD:978-1-4673-8811-5","10.1109/HMI.2016.7449200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449200","ANN with BPP;Microcontroller;Surface electromyography (SEMG);Wavelets","Artificial neural networks;Electrodes;Electromyography;Feature extraction;Muscles;Skin;Wrist","electromyography;gesture recognition;handicapped aids;human computer interaction;medical signal processing;neural nets","ANN;EMG signal processing;SEMG based human computer interface;arm gesture recognition;artificial neural network;electromyogram;hand gesture identification;human-computer interaction;muscles temporal activities;physically challenged patients;surface electromyography","","","","6","","","3-5 March 2016","","IEEE","IEEE Conference Publications"
"Semi natural language algorithm to programming language interpreter","S. Nadkarni; P. Panchmatia; T. Karwa; S. Kurhade","I.T. Department, Sardar Patel Institute of Technology, Mumbai, India","2016 International Conference on Advances in Human Machine Interaction (HMI)","20160409","2016","","","1","4","The conversion of an algorithm to code is still at an early stage. Effective conversion of algorithms mentioned in natural English language to code will enable programmers to focus on logic building and free them of syntactical worries, further it will also aid the visually impaired programmers. Although beneficial, implementation of such a converter encounters numerous challenges like limitations imposed due to semantics of the English language, case frames, etc. In this paper we have introduced an interpreter that is capable of converting algorithms in English to C code whose flexibility of interpretation has been enhanced by using synonyms and by the introduction of a personalised training model whose concept has been outlined below. We have defined the conceptual model along with a user scenario which demonstrates the functioning of our model.","","Electronic:978-1-4673-8810-8; POD:978-1-4673-8811-5","10.1109/HMI.2016.7449190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449190","Case frames;NLP interpreter;Natural Language Processing;Personalized;Trigger words","Computer languages;Natural language processing;Programming;Semantics;Training;Writing","human computer interaction;natural language processing","NLP interpreter;natural language processing;seminatural language algorithm;visually impaired programmers","","","","5","","","3-5 March 2016","","IEEE","IEEE Conference Publications"
"Measurement of efficiency of auditory vs visual communication in HMI: A cognitive load approach","N. Kumar; J. Kumar","Instrument Design & Development Centre, IIT DELHI, NEW DELHI, India","2016 International Conference on Advances in Human Machine Interaction (HMI)","20160409","2016","","","1","8","As Human machine interaction (HMI) is becoming increasingly complex, the need to assess the efficiency of modes of human-machine communication are increasingly becoming relevant. Several methods to analyze the cognitive activity of users for HMI exist like verbal protocols, cognitive task analysis and physiological measures (EEG, MEG & fMRI) etc. In this paper, power spectrum analysis of EEG in parietal and occipital lobes of the human brain has been used for comparative study of efficiency of visual and auditory tasks in HMI. For the same task, both the visual and auditory instructions were given and the observed efficiency correlated with the EEG power spectrum. The results showed that visual channel lead to less brain activity and hence was faster means of machine to human communication when the subject was attending to the task. Further, this paper argues for EEG power spectrum as an objective measure of the human cognitive load caused by the machine, environment and task in the HMI setup.","","Electronic:978-1-4673-8810-8; POD:978-1-4673-8811-5","10.1109/HMI.2016.7449168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449168","Cognitive load;EEG;Human machine interaction","Brain-computer interfaces;Electroencephalography;Physiology;Power measurement;Spectral analysis;Visualization","auditory evoked potentials;cognition;electroencephalography;human computer interaction;medical signal processing;physiology;visual evoked potentials","EEG power spectrum analysis;HMI;MEG;auditory communication;cognitive activity analysis;cognitive load approach;cognitive task analysis;efficiency measurement;fMRI;human machine interaction;occipital lobes;parietal lobes;physiological measures;verbal protocols;visual communication","","","","28","","","3-5 March 2016","","IEEE","IEEE Conference Publications"
"A dialogue monitoring scheme for a virtual doctor","S. Mallios; N. Bourbakis","Department of Computer Science and Engineering, Wright State University, Dayton, OH 45435 USA","2015 National Aerospace and Electronics Conference (NAECON)","20160331","2015","","","249","253","In today's digital world the information exchange has reached very large volumes per minute, assisting people in doing their business from long distances, without their presence being necessary. At the same time, Human Machine Interaction (HMI) devices are used in many places of service and interaction by removing humans from the loop. Although these devices have advanced recently, they are still far away from replacing the human from the interaction loop. Their major problem is that they cannot reliably and efficiently respond to human requests; they mainly behave as ""answer"" machines. In response to this problem we propose a new HMI scheme, capable of offering a better communication and interaction to human users, based on SPN dialogue rather than answers to questions.","","Electronic:978-1-4673-7565-8; POD:978-1-4673-7566-5","10.1109/NAECON.2015.7443077","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443077","SPN dialogue;health monitoring;human-machine interaction;prognosis;virtual doctor","","human computer interaction;interactive systems;medical computing;patient monitoring","HMI devices;SPN dialogue;dialogue monitoring scheme;digital world;human machine interaction;information exchange;interaction loop;virtual doctor","","","","6","","","15-19 June 2015","","IEEE","IEEE Conference Publications"
"A real-time dynamic hand gesture recognition system using kinect sensor","Y. Chen; B. Luo; Y. L. Chen; G. Liang; X. Wu","Wuyi University, Jiangmen, Guangdong Province","2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)","20160225","2015","","","2026","2030","The use of hand gestures provides an attractive alternative to cumbersome interface devices for Human-Computer Interaction (HCI). However, in dynamic gesture recognition area, hand tracking under a complicated environment and gesture spotting namely detecting the start and end point are the two most challenging topics. In our work, a realtime Kinect-based dynamic hand gesture recognition (HGR) system which contains hand tracking, data processing, model training and gesture classification is proposed. In the first stage, two states of the performed hand including open and closed are utilized to achieve gesture spotting and 3D motion trajectories of gestures are captured by Kinect sensor. Further, motion orientation is extracted as the unique feature and Support Vector Machine (SVM) is used as the recognition algorithm in the proposed system. The results of experiments conducted in our database containing 10 Arabic numbers from 0 to 9 and the 26 characters of alphabet show efficiency with an average recognition rate of 95.42% and real-time performance of our method.","","Electronic:978-1-4673-9675-2; USB:978-1-4673-9674-5","10.1109/ROBIO.2015.7419071","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419071","Dynamic hand gesture recognition;Gesture spotting;Kinect 2.0;Skeleton tracking","Feature extraction;Gesture recognition;Hidden Markov models;Real-time systems;Support vector machines;Training;Trajectory","gesture recognition;human computer interaction;image classification;image motion analysis;image sensors;interactive devices;object detection;object recognition;object tracking;support vector machines","3D motion trajectories;HCI;HGR system;Kinect sensor;Kinect-based dynamic hand gesture recognition algorithm;SVM;average recognition rate;data processing;dynamic gesture recognition area;gesture classification;gesture spotting;hand tracking;human computer interaction;interface devices;model training;motion orientation;real-time dynamic hand gesture recognition system;support vector machine","","","","21","","","6-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Efficient Algorithms for Accelerometer-Based Wearable Hand Gesture Recognition Systems","G. Marqués; K. Basterretxea","Digital Electron. Design Group, Univ. of the Basque Country, Bilbao, Spain","2015 IEEE 13th International Conference on Embedded and Ubiquitous Computing","20151228","2015","","","132","139","The rapid increase in the use of robotic systems in industrial and domestic environments makes it necessary the development of more natural interaction procedures. This paper presents the development of a user-specific hand Gesture Recognition System (GRS) based on the information of a single tri-axial accelerometer to recognize 7 different dynamic gestures for natural Human Machine Interaction (HMI). The aim of this paper is to analyze and compare different computational methods for feature extraction, dimensionality reduction, and vector classification in order to select the most suitable combination of signal processing stages that meets the performance requirements for a single-chip, wearable GRS system. These requirements are lag-free response, low size, and low power consumption while keeping high recognition accuracy. Experimental results show that the overall achievable accuracy can be up to 98% for Artificial Neural Network (ANN) and Extreme Learning Machine (ELM) predictors, and 99% for Support Vector Machines (SVM).","","Electronic:978-1-4673-8299-1; POD:978-1-4673-8300-4","10.1109/EUC.2015.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363627","embedded systems;hand gesture recognition;human computer interaction;neural classifiers;wearable computing","Accelerometers;Artificial neural networks;Classification algorithms;Feature extraction;Frequency-domain analysis;Gesture recognition;Time-domain analysis","accelerometers;feature extraction;gesture recognition;human computer interaction;image classification;learning (artificial intelligence);neural nets;support vector machines","ANN;ELM predictor;HMI;SVM;accelerometer-based wearable hand gesture recognition system;artificial neural network;computational method;dimensionality reduction;domestic environment;dynamic gesture;extreme learning machine predictor;feature extraction;industrial environment;lag-free response;low power consumption;natural human machine interaction;natural interaction procedure;performance requirement;recognition accuracy;robotic system;signal processing stage;single tri-axial accelerometer;single-chip;support vector machine;user-specific hand gesture recognition system;vector classification;wearable GRS system","","","","27","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"EEG-Based Perceived Tactile Location Prediction","D. Wang; Y. Liu; D. Hu; G. Blohm","College of Mechatronics and Automation, National University of Defense Technology, Changsha, China","IEEE Transactions on Autonomous Mental Development","20151209","2015","7","4","342","348","Previous studies have attempted to investigate the peripheral neural mechanisms implicated in tactile perception, but the neurophysiological data in humans involved in tactile spatial location perception to help the brain orient the body and interact with its surroundings are not well understood. In this paper, we use single-trial electroencephalogram (EEG) measurements to explore the perception of tactile stimuli located on participants' right forearm, which were approximately equally spaced centered on the body midline, 2 leftward and 2 rightward of midline. An EEG-based signal analysis approach to predict the location of the tactile stimuli is proposed. Offline classification suggests that tactile location can be detected from EEG signals in single trial (four-class classifier for location discriminate can achieve up to 96.76%) with a short response time (600 milliseconds after stimulus presentation). From a human-machine-interaction (HMI) point of view, this could be used to design a real-time reactive control machine for patients, e.g., suffering from hypoesthesia.","1943-0604;19430604","","10.1109/TAMD.2015.2427581","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097691","Electroencephalogram (EEG);prediction;spatial location perception;tactile","Band-pass filters;Electroencephalography;Light emitting diodes;Neuroscience;Solenoids;Time-frequency analysis","electroencephalography;haptic interfaces;human computer interaction;medical signal processing;neurophysiology","EEG measurement;EEG-based signal analysis;human-machine-interaction;neurophysiological data;perceived tactile location prediction;peripheral neural mechanism;single-trial electroencephalogram;tactile perception;tactile spatial location perception;tactile stimuli","","1","","18","","20150429","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"Motion estimation for human-machine interaction","G. M. Phade; P. D. Uddharwar; P. A. Dhulekar; S. T. Gandhe","Electronics and Telecommunication Department, Savitribai Phule University of Pune, India","2014 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)","20151026","2014","","","000149","000154","Human machine interaction is an evolving research area which deals with interactions with machines that will be as natural as an interaction between humans. Vision based motion estimation can also be said as the interpretation of motions via mathematical algorithms. This system have applications in domains such as sign language translation, virtual environments, smart surveillance, controlling robots, control of machines, medical systems etc. The task is challenging due to the accuracy, further the items in the background or distinct features of the users may make recognition more difficult. In this survey, we address these challenges. We provide an overview of current advances in the field. Further, we discuss limitations and outline promising directions of research. A brief overview of methodologies implemented by earlier researcher on vision based gesture recognition for human machine interaction is discussed here.","2162-7843;21627843","CD-ROM:978-1-4799-1811-9; Electronic:978-1-4799-1812-6; POD:978-1-4799-1813-3","10.1109/ISSPIT.2014.7300579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300579","Gesture recognition;Human machine interaction (HMI);Motion estimation","Biomedical monitoring;Estimation;Graphical user interfaces;Monitoring;Personal digital assistants;Radio frequency;Virtual environments","computer vision;gesture recognition;human computer interaction;motion estimation","HMI;background items;human-machine interaction;mathematical algorithms;motion interpretation;user features;vision-based gesture recognition;vision-based motion estimation","","","","16","","","15-17 Dec. 2014","","IEEE","IEEE Conference Publications"
"Recommendations Supporting Situation Awareness in Partially Automated Driver Assistance Systems","F. Wulf; M. Rimini-Döring; M. Arnon; F. Gauterin","Robert Bosch GmbH, Abstatt, Germany","IEEE Transactions on Intelligent Transportation Systems","20150731","2015","16","4","2290","2296","It is believed that automated driving is able to fulfill the demand for comfort and safety in traffic. Recent developments have been able to take over all parts of the driving task in specific situations. However, it remains to the driver to monitor the system's behavior upon errors and to intervene in the case of critical situations. On account of the automation, the driver may not be able to overlook the whole situation in the same way he would do while driving manually. In addition to that, the driver's motivation to perform secondary tasks while being driven enhances these challenges. The research activities presented in this paper are concentrated on the development and the evaluation of certain human-machine interface (HMI) mechanisms. It is hypothesized that such mechanisms have a positive impact on driver's situation awareness (SA) and resulting driving safety (DS). The evaluation of these mechanisms occurred in a driving simulator study. Based on the evaluation results, a system presenting the secondary task's display in the vehicle's head-up display is proposed. Thereby, the driver is expected to be able to keep the vehicle's environment in his peripheral field of view without being distracted too much. At the same time, relevant elements to operate the secondary task should be located on the steering wheel. This is expected to reduce the time needed for steering reactions, as drivers keep at least one hand on the steering wheel. The results suggest that such a system design appears reasonable in order to enhance driver's SA and DS while driving partially automated.","1524-9050;15249050","","10.1109/TITS.2014.2376572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000589","Driving simulator;human–machine interaction;human???machine interaction;partially automated driving;situation awareness (SA)","Automation;Current measurement;Monitoring;Safety devices;Vehicles;Wheels","driver information systems;human computer interaction;road safety","HMI mechanisms;automated driving;driver situation awareness;driving safety;driving simulator;human-machine interface mechanism evaluation;partially automated driver assistance systems;steering wheel;system behavior monitoring;traffic safety;vehicle head-up display","","0","","50","","20141231","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Offloading industrial human-machine interaction tasks to mobile devices and the cloud","L. Wang; A. Canedo","Siemens Corporation, Corporate Technology, Princeton, USA","Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)","20150112","2014","","","1","4","This paper presents a three-tier architecture to offload Human-Machine Interaction (HMI) industrial automation tasks to local mobile devices and then the cloud, to take advantage of distributed computing and processing resources and to add new features to the HMI panel system. To best utilize the merits of each tier, a scheduling algorithm intelligently distributes the HMI tasks among the local HMI panel, mobile devices, and the cloud while taking into consideration their real-time characteristics. We demonstrate the proposed architecture with a real implementation on with a turbine control HMI.","1946-0740;19460740","Electronic:978-1-4799-4845-1; POD:978-1-4799-4844-4","10.1109/ETFA.2014.7005249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7005249","Task offloading;cloud;human-machine interface (HMI);industry automation;mobile technology","Automation;Computer architecture;Mobile communication;Mobile handsets;Performance evaluation;Real-time systems;Runtime","cloud computing;factory automation;human computer interaction;man-machine systems;mobile computing;mobile handsets","HMI panel system;cloud computing;distributed computing resources;distributed processing resources;local HMI panel;mobile devices;offload HMI industrial automation tasks;offload human-machine interaction industrial automation tasks;three-tier architecture;turbine control HMI","","0","","3","","","16-19 Sept. 2014","","IEEE","IEEE Conference Publications"
"A happiness-oriented home care system for elderly daily living","Y. Y. Ou; P. Y. Shih; T. W. Kuan; S. H. Shih; J. F. Wang; J. S. Wu","Dept. of Electr. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","2014 International Conference on Orange Technologies","20141120","2014","","","193","196","Currently the modern developing home-care systems highlight the functionalities on bio-signals measurement, security surveillance and health care, however most of them work independently. In this paper, a newly warming-care framework for elderly is proposed, not only to reach the aforementioned services, but also including following kindly services, that is, the remote monitoring, the web camera management, the emergency call for help, the behavior recognition and feedback, and the remote control entertainment services, to reach a comprehensive humanistic-caring system. The proposed framework is motivated by the individual alphabet on “HAPPINESS” which are redefined and interpreted as “Health”, “Ability”, “Protection”, “Personalization”, “Interaction”, “Nursing”, “Entertainment”, “Succor” and “Smile”. Three main services are spotlighted to achieve the goals described below. The Web-based Central Camera Management Service (WCCMS) is a real-time remote monitoring function that a caregiver can pay attention to care elderly anytime and anywhere through web services; the Multimodal Human-Machine Interaction Service (MHMIS) provides the audio-visual cognitive functions to interact with elderly, and the Web-based User Management Service (WUMS) gives user a smart HMI interface including bio-signal measurement, help button, remote control, and hospital appointment scheduling functionalities. To evaluate the proposed framework usability, MOS (Mean Opinion Score) is applied and average MOS 4.2 score is acquired that reveals the proposed system expectable.","","Electronic:978-1-4799-6284-6; POD:978-1-4799-6285-3","10.1109/ICOT.2014.6956632","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6956632","HAPPINESS-oriented home care system;multiple human-machine interaction service;web-based management service","Cameras;Customer services;Entertainment industry;Hospitals;Remote monitoring;Senior citizens","Web services;assisted living;cameras;geriatrics;human computer interaction;patient monitoring;telemedicine","MHMIS;MOS 4.2 score;WCCMS;WUMS;Web camera management;Web services;Web-based central camera management service;Web-based user management service;audio-visual cognitive function;behavior recognition;biosignal measurement;biosignals measurement;comprehensive humanistic-caring system;elderly daily living;feedback;framework usability;happiness-oriented home care system;health care;help button;hospital appointment scheduling functionality;mean opinion score;multimodal human-machine interaction service;real-time remote monitoring function;remote control entertainment services;security surveillance;smart HMI interface;warming-care framework","","2","","11","","","20-23 Sept. 2014","","IEEE","IEEE Conference Publications"
"An initial approach towards the implementation of human error identification services for antifragile systems","C. A. Ramirez; M. Itoh","Department of Risk Engineering, University of Tsukuba, Japan","2014 Proceedings of the SICE Annual Conference (SICE)","20141027","2014","","","2031","2036","This paper describes a theoretical approach to implement human error identification services for antifragile systems. The services provide data analysis and maintain a human error database that is fed and used by multiple software systems. Thus, systems take advantage of the shared human error database by integrating its knowledge into their own antifragile strategy to self-adjust data policies and user interface input requirements. This encourages an increased rate of changes in the internal models of the external physical objects and environments that antifragile systems might take into account in their learning process. Initial considerations of human-machine interaction issues that might arise in antifragile systems are discussed.","","Electronic:978-4-9077-6446-3; POD:978-1-4799-6548-9","10.1109/SICE.2014.6935315","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935315","Antifragility;HMI;Human error;Human error database","Adaptation models;Automation;Context;Databases;Resource management;Software systems","data analysis;human computer interaction;human factors;user interfaces","antifragile systems;data analysis;data policies;human error identification services;human-machine interaction;learning process;shared human error database;user interface input requirements","","0","","11","","","9-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Automatic emotion recognition in video","R. KalaiSelvi; P. Kavitha; K. L. Shunmuganathan","Department of CSE, RMK Engineering College, Chennai","2014 International Conference on Green Computing Communication and Electrical Engineering (ICGCCEE)","20141016","2014","","","1","5","Automatic recognition of emotion is becoming increasingly important component in Human-Machine Interaction (HMI) systems. Recognizing human facial emotion by computer is interesting and challenging problem. Emotions are the key semantic component of human communication. This paper presents the system for recognizing emotions through facial expression displayed in the video. Audio-visual emotion recognition can be carried out with the video sequence. The video sequence is a mixture of both the audio and video information. But in this paper, we are dealing only with the video information to recognize the emotion of a character. This process is carried out by the selection of the target frame followed by the segmentation of the video sequence. Facial feature tracking is performed to extract features. The face is classified in to different Action Units. Face emotions are recognized by using Dynamic Bayesian Network. The results so far shows the approach to have a promising success rate.","","Electronic:978-1-4799-4982-3; POD:978-1-4799-4981-6","10.1109/ICGCCEE.2014.6921398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6921398","Action Unit recognition;Dynamic Bayesian Network;Facial Feature Tracking;Video segmentation","Emotion recognition;Face;Face recognition;Facial features;Feature extraction;Hidden Markov models;Video sequences","belief networks;emotion recognition;face recognition;feature extraction;human computer interaction;image classification;image segmentation;image sequences;object tracking;video signal processing","HMI systems;action units;audio information;audio-visual emotion recognition;automatic emotion recognition;dynamic Bayesian network;facial expression;facial feature tracking;feature extraction;human communication key semantic component;human facial emotion recognition;human-machine interaction systems;video information;video sequence segmentation","","2","","20","","","6-8 March 2014","","IEEE","IEEE Conference Publications"
"Robust Hand Detection and Tracking Based on Monocular Vision","H. Liang; Y. Zhao; J. Wei; D. Quan; R. Cheng; Y. Wei","Sch. of Electron. & Comput. Eng., Peking Univ., Shenzhen, China","2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics","20141009","2014","2","","134","137","Vision based hand tracking is an important area of human machine interaction (HCI) and virtual reality techniques. However, it is still a great challenge. Due to the complicated environment and various hand appearances, it is difficult to realize stable and long-term tracking. In this paper, we proposed an effective approach to detect and track hand with a normal webcam. An integrating multi-cue detector with skin color and hand classifier is used to initialize the tracking region and find appearance information during tracking. Also a median flow tracker is integrated which utilizing the motion information to enhance the accuracy in short-term. We realize an automatic system of stable and long-term hand tracking, which can detect and track pre-trained frontal view hand gesture. Experiments show the good performance of our approach.","","Electronic:978-1-4799-4955-7; POD:978-1-4799-4954-0","10.1109/IHMSC.2014.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911466","hand detection;hand tracking;human computer interaction(HCI)","Accuracy;Detectors;Feature extraction;Image color analysis;Robustness;Skin;Tracking","computer vision;gesture recognition;human computer interaction;image colour analysis;image motion analysis;object tracking;palmprint recognition;virtual reality","HCI;frontal view hand gesture;hand classifier;human machine interaction;median flow tracker;monocular vision;motion information;multicue detector;robust hand detection;skin color;virtual reality;vision based hand tracking","","0","","17","","","26-27 Aug. 2014","","IEEE","IEEE Conference Publications"
"A Novel Multimedia Interactive System for Public Show and Presentations","M. Gaudina; S. Schiappacasse; L. Lagomarsino; E. Bellanti; G. Vercelli","Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy","2014 Eighth International Conference on Complex, Intelligent and Software Intensive Systems","20141002","2014","","","543","546","Holographic interactivity is nowadays a promising research topic within HCI field, mainly due to recent technological improvements. Moreover, low-cost off-the shelf components are widely availables, with respect to the last century situation for traditional human-machine interaction paradigms. The way of displaying information and data communication are now much more robust and solid than in the past, allowing better user experiences (Ux) than before in terms of presence and immersion. The paper presents a novel interaction system based on holographic and multi-touch technologies well suited for shows and interactive talks. The performer/presenter operates behind a vertical touch enabled transparent holographic panel where multimedia contents are projected and directly manipulated. This type of communication is much more cogent and immersive than any other, since both the presenter and the public interact facing each other with the possibility of focusing their attention on the same interspersed interactive elements. Furthermore, the system relies on a web based cross-platform framework allowing both proximal and remote interaction and visualization on smartphones, tablets and internet enabled devices in general. Preliminary interviews have underlined the goodness of this new interaction paradigm suggesting that this could be a strong base of a much larger platform for many and different uses.","","CD-ROM:978-1-4799-4326-5; Electronic:978-1-4799-4325-8; POD:978-1-4799-1677-1","10.1109/CISIS.2014.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915571","","Business;Internet;Multimedia communication;Software;Tactile sensors;Three-dimensional displays","Internet;computer aided instruction;human computer interaction;multimedia systems;touch sensitive screens","HCI field;Web based cross-platform framework;holographic interactivity;holographic technology;human computer interface;multimedia contents;multimedia interactive system;multitouch technology;proximal interaction;public presentation;public show;remote interaction;user experience;vertical touch enabled transparent holographic panel","","0","","16","","","2-4 July 2014","","IEEE","IEEE Conference Publications"
"One dimensional ring type growing SOM with asymmetric neighborhood function and its application to a hand shape instruction learning system","T. Kuremoto; T. Otani; M. Obayashi; K. Kobayashi; S. Mabu","Dept. Inf. Sci. & Eng., Yamaguchi Univ., Ube, Japan","15th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","20140901","2014","","","1","6","An asymmetric neighborhood function was proposed by Aoki and Aoyagi to instead of symmetric neighborhood function in conventional Kohonen's self-organizing map (SOM) to avoid topological twist of the order of units during training process. Meanwhile, a one dimensional ring type growing SOM was proposed by Ohta and Saito to reduce the unnecessary increasing of units of conventional 2-D growing SOM. In this paper, we adopt the asymmetric neighborhood to a parameterless growing SOM (PL-G-SOM) proposed by Kuremoto et al. to construct a novel SOM: One dimensional ring type growing SOM using asymmetric neighborhood function (One-D-R-A-G-SOM). The proposed SOM is applied to instruction recognition and learning system with input of hand shapes for human-machine-interaction (HMI), especially for users of speech handicapped people. The effectiveness of the proposed method was confirmed by the experiments comparing with systems using conventional SOMs.","","Electronic:978-1-4799-5604-3; POD:978-1-4799-5605-0","10.1109/SNPD.2014.6888741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6888741","PL-G-SOM;human-machine-interaction (HMI);reinforcement learning;self-organzing map (SOM)","Educational institutions;Learning systems;Robots;Shape;Thumb;Training;Vectors","computer aided instruction;handicapped aids;human computer interaction;self-organising feature maps;sign language recognition","1D ring type growing SOM;HMI;Kohonen self-organizing map;PL-G-SOM;asymmetric neighborhood function;hand shape instruction learning system;human-machine-interaction;instruction recognition system;one-D-R-A-G-SOM;parameterless growing SOM;speech handicapped people;training process","","0","","23","","","June 30 2014-July 2 2014","","IEEE","IEEE Conference Publications"
"Effects of human-machine interaction mechanisms on situation awareness in partly automated driving","F. Wulf; K. Zeeb; M. Rimini-Döring; M. Arnon; F. Gauterin","Robert Bosch GmbH, Abstatt, Germany","16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)","20140130","2013","","","2012","2019","In recent years, one of the goals of driver assistance systems has been to relieve the driver of parts of his burden of driving. Current developments are able to take over full control of the vehicle in specific use cases. Automated driving in traffic jams is seen as the next step towards automated driving. One of the main challenges is ensuring the driver's ability to take back responsibility when being driven by the car. The assumption that drivers tend to perform secondary tasks creates a target conflict. Within this context, it is the aim of the current study to analyze the impacts of an exemplary secondary task and certain Human-Machine Interaction (HMI) mechanisms on the driver's level of situation awareness and the resulting driving safety. The implemented HMI mechanisms are a “driver's safety device” and a “video image”. While it is hypothesized that the secondary task has a negative influence on situation awareness, the HMI mechanism's effect is supposed to be positive. In addition, the overall user's acceptance will also be analyzed. The results show that the implemented driver's safety device has no effect on situation awareness but is still able to support driving safety by assisting the driver in the execution of actions. The video image has a positive effect on situation awareness but because the complacency-effect is enhanced its effect on driving safety is negligible. As assumed, the secondary task has a negative impact on situation awareness and driving safety.","2153-0009;21530009","Electronic:978-1-4799-2914-6; POD:978-1-4799-2915-3; USB:978-1-4799-2913-9","10.1109/ITSC.2013.6728525","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728525","Driving Simulator;Human-Machine Interaction;Partly Automated Driving;Situation Awareness","Automation;Automotive components;Current measurement;Man machine systems;Safety devices;Vehicles","automobiles;driver information systems;human computer interaction;road traffic","HMI mechanisms;automated driving;car;complacency effect;driver assistance systems;driver safety device;driver secondary tasks;driver situation awareness level;driving safety;exemplary secondary task;human-machine interaction mechanisms;traffic jams;user acceptance;video image","","1","","29","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Autonomous input management for Human Interaction-oriented systems design","M. Podpora; A. Kawala-Janik; M. Kiernan","Fac. of Electr. Eng., Autom. Control & Inf., Opole Univ. of Technol., Opole, Poland","2013 Federated Conference on Computer Science and Information Systems","20131107","2013","","","143","144","In this paper evaluation of a policy-based algorithm for video inputs switching is presented. The term `data quality' is not trivial for Human-Machine Interaction systems, yet a simple and efficient algorithm is needed for choosing the most valuable video source. This becomes particularly important for systems that support functional decomposition of image processing algorithm, which are designed for non-optimal working environment. In this paper an autonomous input management system is proposed, which consists of a data quality evaluation algorithm and a simple decision algorithm.","","Electronic:978-83-60810-52-1; POD:978-1-4673-4471-5; USB:978-83-60810-53-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6643989","Autonomic Systems;Decision Systems;Distributed Systems;Human-Machine Interaction (HMI);Machine Vision","Algorithm design and analysis;Educational institutions;Lighting;Man machine systems;Streaming media;Switches;Visualization","human computer interaction;video signal processing","autonomous input management system;data quality evaluation algorithm;decision algorithm;functional decomposition;human interaction-oriented system design;human-machine interaction system;image processing algorithm;policy-based algorithm;video inputs switching","","0","","4","","","8-11 Sept. 2013","","IEEE","IEEE Conference Publications"
"Topics in Biometric Human-Machine Interaction Security","R. Kannavara; K. L. Shippy","Security Center of Excellence, Intel Corp, Hillsboro, OR, USA","IEEE Potentials","20131101","2013","32","6","18","25","Biometrics is the science and technology of measuring and statistically analyzing biological data. As applied to computing and human-machine interaction (HMI), biometric applications deal with recognizing the individual or deciphering the individual's conversation (e.g., in the form of voice commands or gestures) or collecting and analyzing data regarding the individual's health and emotional status.These applications inherently deal with personally identifiable information (PII), which ultimately has to be stored somewhere, retrieved at some point of time, processed, and probably stored again, perhaps over a wireless channel.","0278-6648;02786648","","10.1109/MPOT.2013.2248891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651640","","Authentication;Biometrics (access control);Cryptography;Databases;Gesture recognition;Measurement","biometrics (access control);data privacy;human computer interaction;security of data","HMI;PII;biological data measurement;biometric application;biometric human-machine interaction security;data analysis;data collection;emotional status;gestures;health status;personally identifiable information;statistical analysis;voice commands;wireless channel","","2","","12","","","Nov.-Dec. 2013","","IEEE","IEEE Journals & Magazines"
"Pro-active content managing system for efficient human machine interaction in data intensive environments","A. N. N. Lee; Y. Evchina; A. Dvoryanchikova; J. L. M. Lastra","Department of Production Engineering, Tampere University of Technology Foundation (TUT), Finland","2013 11th IEEE International Conference on Industrial Informatics (INDIN)","20131010","2013","","","790","796","The informational flow in modern technological systems is intensive due to multiple embedded devices, which leads to informational overload for users, causes time lost and decreases the reliability of the performance of a human-machine system. There is a need for efficient managing of information in order to display it to a particular user accordingly to his/her current needs. This paper presents the concept of a Virtual Control Room (VCR) which is a proactive content-managing context-aware system aiming to facilitate human-machine interaction and the process of human decision/making in data intensive environments. The system collects, models, and reasons the context information and displays it in a personalized way via pro-active and adaptive multimodal Human Machine Interfaces (HMIs) on mobile devices. As a result, users can monitor and control the system from any location in a comfortable manner. The breakthrough is seen in a semantic Web based solution, which considers ontological dynamic context models with two level reasoning on top, and adaptive HMIs which support functionality on different mobile devices with introduction of modern technologies like 3D and augmented reality. The VCR concept is illustrated using two possible application domains, which are seen as important and challenging both from a socio-economic and from a technical perspective: building and manufacturing domains.","1935-4576;19354576","Electronic:978-1-4799-0752-6; POD:978-1-4799-0750-2; USB:978-1-4799-0751-9","10.1109/INDIN.2013.6622985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6622985","Building automation;context-awareness;human machine interface;industrial systems;manufacturing;ontologies","Adaptation models;Adaptive systems;Context;Context modeling;Engines;Monitoring;Ontologies","augmented reality;content management;human computer interaction;mobile computing;ontologies (artificial intelligence);semantic Web;user interfaces","3D technology;HMI;VCR concept;augmented reality technology;building domain;context information collection;context information modelling;context information reasoning;data intensive environments;embedded devices;human decision making process;human machine interaction;human-machine system performance reliability reduction;information management;informational flow;informational overload;manufacturing domain;mobile devices;ontological dynamic context models;proactive adaptive multimodal human machine interfaces;proactive content-management context-aware system;semantic Web-based solution;socio-economic domain;system control;system monitoring;technological systems;two-level reasoning;virtual control room","","0","","35","","","29-31 July 2013","","IEEE","IEEE Conference Publications"
"User experience evaluation in an automotive context","M. Körber; A. Eichinger; K. Bengler; C. Olaverri-Monreal","Dept. of Mech. Eng., Tech. Univ. Munchen, Munich, Germany","2013 IEEE Intelligent Vehicles Symposium Workshops (IV Workshops)","20130930","2013","","","13","18","Tough competition in the automobile market makes it very important to exceed customer expectations with in-vehicle devices or applications in order to stand out in an already saturated market. Research on human-machine interaction (HMI) showed that user satisfaction is not only influenced by usability factors but also by user experience (UX). Since UX in the automotive context has not yet been comprehensively investigated, this article presents a feasible research method for the measurement of UX. We rely on the fulfillment of psychological needs as a user experience measurement and conducted three online surveys to develop a questionnaire for that purpose. We analyze nine need scales, each with 10 items, and reduced the item count afterwards for a shorter form of the questionnaire. Results reveal that the method successfully measured the intended needs. Future work with respect to a further extension and improvement of the method is discussed.","","Electronic:978-1-4799-0795-3; POD:978-1-4799-0793-9","10.1109/IVWorkshops.2013.6615219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6615219","","Automotive engineering;Context;Correlation;Reliability;Standards;Usability;Vehicles","automobile industry;ergonomics;human computer interaction","HMI;UX;automobile market;automotive context;customer expectations;human-machine interaction;in-vehicle devices;psychological needs;usability factors;user experience evaluation;user experience measurement","","1","","22","","","23-23 June 2013","","IEEE","IEEE Conference Publications"
"Hands tracking with self-occlusion handling in cluttered environment","B. J. Chen; C. M. Huang; A. S. Liu; T. E. Tseng; L. C. Fu","Department of Electrical Engineering, National Taiwan University, Taiwan, ROC","2013 9th Asian Control Conference (ASCC)","20130923","2013","","","1","8","This paper presents a two-hands tracking method with a monocular camera for human machine interaction (HMI). To clarify the face of the user and his/her hands, the face is also tracked in our method. The targets are tracked independently when they are far from each other; however, they are merged with dependent likelihood measurements in higher dimension while they are likely to interrupt each other. While one target is being tracked in the independent situation, other targets are masked to decrease the skin color disturbances on the tracked one. Multiple cues, including the combination of the locally discriminative color weighted image and the back-projection image of the reference color model, the motion history image and the gradient orientation feature, are employed to verify the hypotheses originated from the particle filter. On the other hand, when the targets are closing or even overlapping, the multiple importance sampling (MIS) particle filter generates the tracking hypotheses of the merged targets by the skin blob reasoning and the depth order estimation. These joint hypotheses are then evaluated by the visual cues of occluded face template, hand shape gradient orientation, motion continuity and forearm equation. The experimental results present the real-time efficiency and the robustness in comparison with the state-of-the-art human pose estimation method.","","Electronic:978-1-4673-5769-2; POD:978-1-4673-5766-1; USB:978-1-4673-5768-5","10.1109/ASCC.2013.6606126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606126","","Face;Image color analysis;Joints;Shape;Skin;Target tracking","cameras;clutter;face recognition;gradient methods;human computer interaction;image colour analysis;image motion analysis;importance sampling;object tracking;particle filtering (numerical methods);shape recognition;target tracking","HMI;MIS particle filter;back-projection image;cluttered environment;depth order estimation;discriminative color weighted image;face tracking;forearm equation;gradient orientation feature;hand shape gradient orientation;human machine interaction;likelihood measurements;monocular camera;motion continuity;motion history image;multiple importance sampling;occluded face template;reference color model;self-occlusion handling;skin blob reasoning;skin color disturbances;target tracking;two-hands tracking method;visual cues","","0","","14","","","23-26 June 2013","","IEEE","IEEE Conference Publications"
"Imaging and HMI: Fondations and complementarities","N. Triki; M. Kallel; M. S. Bouhlel","Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), Sfax, Tunisia","2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT)","20130321","2012","","","25","29","Nowadays, the new technologies of image processing and Human Machine Interaction (HMI) are mostly linked to the scientific domains of research (medicine, transport, etc). Indeed, the emergence of the tactile interfaces as well as the gestural interfaces allows increasing the physical world which surrounds us with the digital information. It also allows us to use natural hand gestures to interact with this information which is a digital image. In this paper, we describe the basic concepts of the images processing as well as the HMI foundations. Then, we identify the gestural human interaction as well as its relation with the imaging.","","Electronic:978-1-4673-1658-3; POD:978-1-4673-1657-6","10.1109/SETIT.2012.6481884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6481884","Human Machine Interaction (HMI);digital image processing;gestures","Band pass filters;Computers;Digital images;Hidden Markov models;Image color analysis;Image segmentation;Imaging","gesture recognition;haptic interfaces;human computer interaction;image processing","HMI;digital image;digital information;gestural human interaction;gestural interfaces;human machine interaction;image processing;natural hand gestures;tactile interfaces","","1","","13","","","21-24 March 2012","","IEEE","IEEE Conference Publications"
"Improving Vehicle Fleet Fuel Economy via Learning Fuel-Efficient Driving Behaviors","O. Linda; M. Manic","Comput. Sci. Dept., Univ. of Idaho, Idaho Falls, ID, USA","2012 5th International Conference on Human System Interactions","20130307","2012","","","137","143","Reducing the fuel consumption of road vehicles has the potential to decrease environmental impact of transportation as well as achieve significant economical benefits. This paper proposes a novel methodology for improving the fuel economy of vehicle fleets via learning fuel-efficient driving behaviors. Vehicle fleets composed of large number of heavy vehicles routinely perform runs with different drivers over a set of fixed routes. While all drivers might achieve on-time and safe driving performance their actual driving behaviors and the subsequent fuel economy can vary substantially. The proposed Intelligent Driver System (IDS) utilizes vehicle performance data combined with GPS information on fixed routes to incrementally build a model of the historically most fuel efficient driving behavior. During driving, the calculated optimal velocity for specific location is compared to the current vehicle state and a fuzzy logic PD controller is used to compute the optimal control action. The control action can be projected to the drivers via a specialized HMI or used directly as a predictive cruise control to achieve overall fuel economy improvements. The method has been validated on a simulated heavy vehicle model, showing potential for substantial fuel economy improvements.","2158-2246;21582246","Electronic:978-0-7695-4894-4; POD:978-1-4673-4498-2","10.1109/HSI.2012.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6473775","Driving Behaviors;Fuel Economy;Fuzzy Logic Control;Machine Learning;Vehicle Fleet","Artificial intelligence;Fuel economy;Fuzzy logic;PD control;Pragmatics;Vehicles","PD control;control engineering computing;driver information systems;fuel economy;fuzzy control;human computer interaction;learning (artificial intelligence);optimal control;road vehicles","GPS information;Global Positioning System;IDS;economical benefit;fuel consumption reduction;fuel economy improvement;fuel-efficient driving behavior;fuzzy logic PD controller;human-machine interaction;intelligent driver system;learning;optimal control;proportional-derivative controller;road vehicle;specialized HMI;vehicle fleet fuel economy;vehicle performance data","","2","2","13","","","6-8 June 2012","","IEEE","IEEE Conference Publications"
"Application of neural networks in emotional speech recognition","M. Bojanić; V. Crnojević; V. Delić","Faculty of Technical Sciences, University of Novi Sad, Trg Dositeja Obradovi&#x0107;a 6, Serbia","11th Symposium on Neural Network Applications in Electrical Engineering","20130128","2012","","","223","226","Emotional speech recognition (ESR) from the aspect of human-machine interaction (HCI) is a prerequisite for the framework of interacting partners within the HCI. This paper addresses the application of neural network (NN) in ESR. The performance of NN is tested using three different feature sets which are basis for ESR: prosodic features, spectral features and a set of their combination. The results of these feature sets are compared using several network topologies and two training algorithms. It has been shown that using joint prosodic-spectral feature set as input to three layer feed-forward NN trained with back-propagation algorithm has the best performance in 5-class emotional speech recognition task.","","Electronic:978-1-4673-1572-2; POD:978-1-4673-1569-2","10.1109/NEUREL.2012.6420016","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6420016","emotional speech recognition;neural network","Accuracy;Emotion recognition;Feature extraction;Network topology;Neurons;Speech;Speech recognition","backpropagation;emotion recognition;human computer interaction;neural nets;speech recognition","ESR;HCI;NN;backpropagation algorithm;emotional speech recognition;human-machine interaction;network topologies;neural network application;prosodic features;spectral features","","3","","13","","","20-22 Sept. 2012","","IEEE","IEEE Conference Publications"
"Facial expression recognition via Gabor wavelet and structured sparse representation","T. Chen; F. Su","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China","2012 3rd IEEE International Conference on Network Infrastructure and Digital Content","20130124","2012","","","420","424","Automatically facial expression recognition (FER) has become more and more important today, making machine understand human's emotion by expression having various potential applications, especially in the field of human machine interaction (HCI). But FER still remains a challenge problem in computer vision as the subtleness of facial expression is difficult to capture and the robustness of the recognition in various situation is also hard to guarantee. In this paper, a Gabor wavelet and structured sparse representation based classification (SSRC) are proposed aiming to solve the FER problem. The Gabor wavelet filter is used to extract the subtle facial expression, and the structured sparse representation based classification (SSRC) is used for classifying the test images robustly. Unlike sparse representation based classification (SRC), the SSRC explicitly takes structure of the dictionary into account for a better classification. Experimental results show the better performance of our proposed method compared with other traditional methods, especially more robust in case of facing corruption or occlusion.","2374-0272;23740272","Electronic:978-1-4673-2204-1; POD:978-1-4673-2201-0","10.1109/ICNIDC.2012.6418787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418787","Facial expression recognition;Gabor wavelet;Structured sparse representation","Dictionaries;Face;Face recognition;Feature extraction;Humans;Image recognition;Robustness","Gabor filters;computer graphics;emotion recognition;face recognition;human computer interaction;image classification;wavelet transforms","Gabor wavelet filter;computer vision;facial expression recognition;human emotion;human machine interaction;image classification;occlusion;structured sparse representation based classification","","2","","9","","","21-23 Sept. 2012","","IEEE","IEEE Conference Publications"
"Affect recognition using EEG signal","H. Xu; K. N. Plataniotis","The Edward S. Rogers Sr. Dept. of Electrical and Computer Engineering, University of Toronto 10 Kings College Road, Toronto, ON, Canada, M5S 3G4","2012 IEEE 14th International Workshop on Multimedia Signal Processing (MMSP)","20121110","2012","","","299","304","Emotion states greatly influence many areas in our daily lives, such as: learning, decision making and interaction with others. Therefore, the ability to detect and recognize one's emotional states is essential in intelligence Human Machine Interaction (HMI). The aim of this study was to develop a new system that can sense and communicate emotion changes expressed by the Central Nervous System (CNS) through the use of EEG signals. More specifically, this study was carried out to develop an EEG-based subject-dependent affect recognition system to quantitatively measure and categorize three affect states: Positively excited, neutral and negatively excited. In this paper, we discussed implementation issues associated with each key stage of a fully automated affect recognition system: emotion elicitation protocol, feature extraction and classification. EEG recordings from 5 subjects with IAPS images as stimuli from the eNTERFACE06 database were used for simulation purposes. Discriminating features were extracted in both time and frequency domains (statistical, narrow-band, HOC, and wavelet entropy) to better understand the oscillatory nature of the brain waves. Through the use of k Nearest Neighbor classifier (kNN), we obtained mean correct classification rates of 90.77% on the three emotion classes when K equals 5. This demonstrated the feasibility of brain waves as a mean to categorize a user's emotion state. Secondly, we also assessed the suitability of commercially available EEG headsets such as Emotive Epoc for emotion recognition applications. This study was carried out by comparing the sensor location, signal integrity with those of Biosemi Active II. A new set of recognition performance was presented with reduced number of channels.","","Electronic:978-1-4673-4572-9; POD:978-1-4673-4570-5; USB:978-1-4673-4571-2","10.1109/MMSP.2012.6343458","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6343458","","Biomedical monitoring;Brain models;Electrodes;Electroencephalography;Emotion recognition;Feature extraction","brain-computer interfaces;electroencephalography;emotion recognition;entropy;feature extraction;human computer interaction;neurophysiology;statistical analysis;time-frequency analysis;wavelet transforms","CNS;EEG headsets;EEG recordings;EEG-based subject-dependent affect recognition system;Emotive Epoc;HMI;HOC;IAPS images;central nervous system;decision making;eNTERFACE06 database;emotion elicitation protocol;emotional state detection;emotional state recognition;feature classification;feature extraction;frequency domains;fully-automatic affect recognition system;intelligence human machine interaction;k-nearest neighbor classifier;kNN classifier;learning;mean correct classification rates;narrow-band;negatively excited states;neutral states;oscillatory brain waves;positively excited states;sensor location;signal integrity;simulation purposes;statistical analysis;time domains;wavelet entropy","","7","","15","","","17-19 Sept. 2012","","IEEE","IEEE Conference Publications"
"A Fast Gesture Recognition Scheme for Real-Time Human-Machine Interaction Systems","C. H. Lai","Smart Network Syst. Inst. Inst. for Inf. Ind., Taipei, Taiwan","2011 International Conference on Technologies and Applications of Artificial Intelligence","20120102","2011","","","212","217","In recent years, the gesture control technique has become a new developmental trend for many human-based electronics products. This technique let people can control these products more naturally, intuitively and conveniently. In this paper, a fast gesture recognition scheme is proposed to be an interface for the human-machine interaction (HMI) of systems. This paper presents some low-complexity algorithms and gestures to reduce the gesture recognition complexity and be more suitable for controlling real-time computer systems. Besides, this paper also implements a HMI interface for a telematic service system to valid the performance of the proposed scheme and to confirm the proposed is suitable to be used to develop a HMI of telematic service systems for the in-vehicle environment. The experimental results show that the proposed scheme can work well in a real-time service system.","2376-6816;23766816","Electronic:978-0-7695-4601-8; POD:978-1-4577-2174-8","10.1109/TAAI.2011.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120746","Gesture recognition;human-machine interaction (HMI);telematic service system","Feature extraction;Gesture recognition;Image color analysis;Man machine systems;Noise;Vehicles;Videos","gesture recognition;human computer interaction;telecommunication computing","HMI interface;gesture control technique;gesture recognition scheme;human-based electronics products;in-vehicle environment;low-complexity algorithms;real-time human-machine interaction systems;telematic service system","","0","","21","","","11-13 Nov. 2011","","IEEE","IEEE Conference Publications"
"ACP theory based plant human machine interaction evaluation","X. Liu; X. Shen; D. Fan","The State Key Laboratory of Intelligent Control and Management of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","Proceedings of 2011 IEEE International Conference on Service Operations, Logistics and Informatics","20110825","2011","","","116","120","It's an important need for a large chemical plant to roundly and deeply evaluate the design prototype of plant human machine interaction (HMI) using in the control room. To meet this need, we propose an evaluation method based on the ACP (Artificial system, Computational experiment, and Parallel execution) theory. A plant operator agent is created in the method and it is composed of perception, cognition, and execution processors, short-term memory, and long-term memory. The operator agent is used as a virtual subject, and the HMI can be evaluated by behavior simulation, from the viewpoints of shortening fault detection and isolation (FDI) track and decreasing operator's physical and mental workloads. The proposed method shows that the ACP theory is useful for the HMI evaluation.","","Electronic:978-1-4577-0574-8; POD:978-1-4577-0573-1","10.1109/SOLI.2011.5986539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5986539","ACP;fault detection and isolation;human machine interaction;plant operation","Frequency modulation;Pipelines;Switches","chemical industry;fault diagnosis;human computer interaction;man-machine systems;process control","ACP theory;artificial system;computational experiment;fault detection;fault isolation;parallel execution;plant human machine interaction evaluation;plant operator agent","","0","","7","","","10-12 July 2011","","IEEE","IEEE Conference Publications"
"A Framework for Automatic Human Emotion Classification Using Emotion Profiles","E. Mower; M. J. Mataric; S. Narayanan","Department of Electrical Engineering, University of Southern California, University Park, Los Angeles, California, USA","IEEE Transactions on Audio, Speech, and Language Processing","20110502","2011","19","5","1057","1070","Automatic recognition of emotion is becoming an increasingly important component in the design process for affect-sensitive human-machine interaction (HMI) systems. Well-designed emotion recognition systems have the potential to augment HMI systems by providing additional user state details and by informing the design of emotionally relevant and emotionally targeted synthetic behavior. This paper describes an emotion classification paradigm, based on emotion profiles (EPs). This paradigm is an approach to interpret the emotional content of naturalistic human expression by providing multiple probabilistic class labels, rather than a single hard label. EPs provide an assessment of the emotion content of an utterance in terms of a set of simple categorical emotions: anger; happiness; neutrality; and sadness. This method can accurately capture the general emotional label (attaining an accuracy of 68.2% in our experiment on the IEMOCAP data) in addition to identifying underlying emotional properties of highly emotionally ambiguous utterances. This capability is beneficial when dealing with naturalistic human emotional expressions, which are often not well described by a single semantic label.","1558-7916;15587916","","10.1109/TASL.2010.2076804","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5585726","Emotion profiles;multimodal emotion classification;nonprototypical emotions","Accuracy;Databases;Eyebrows;Feature extraction;Hidden Markov models;Humans;Support vector machines","emotion recognition;human computer interaction;image classification","HMI systems;affect-sensitive human-machine interaction systems;automatic emotion recognition;automatic human emotion classification;emotion profiles;human emotional expressions;multiple probabilistic class labels;single hard label;single semantic label","","50","","40","","20100927","July 2011","","IEEE","IEEE Journals & Magazines"
"Inducing Genuine Emotions in Simulated Speech-Based Human-Machine Interaction: The NIMITEK Corpus","M. Gnjatovic; D. Rosner","Otto-von-Guericke-University Magdeburg, Magdeburg and University of Novi Sad, Novi Sad","IEEE Transactions on Affective Computing","20110106","2010","1","2","132","144","Emotional corpora provide an important empirical foundation for investigation when researchers aim at implementing emotion-aware spoken dialog systems. One of the fundamental research questions is how to acquire an appropriate, realistic emotion corpus. The primary aim of this paper is to address the methodological desiderata in producing emotion corpora in human-machine interaction (HMI). It proposes a substantial refinement of the Wizard-of-Oz (WOZ) technique in order that a scenario designed to elicit affected speech in HMI could result in realistic and useful data. In addition, the paper reports about the NIMITEK corpus of affected behavior in HMI produced during a refined WOZ simulation. The evaluation of the corpus with respect to the perception of its emotional content demonstrated that the corpus contains recordings of emotions that were overtly signaled. The range of emotional reactions is indicative of the kind of emotional reactions than can be expected to occur in the interaction with the sort of spoken dialog systems considered in this study. Since the subjects were not restricted by given predetermined linguistic constraints on the language to use, their utterances are indicative of the way in which nontrained, nontechnical users probably like to converse with conversational agents as well.","1949-3045;19493045","","10.1109/T-AFFC.2010.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661765","Affective computing;emotional corpora;methods for emotion elicitation.;methods of data collection","Computational modeling;Emotion recognition;Games;Man machine systems;Robots;Speech recognition","emotion recognition;human computer interaction;interactive systems;speech recognition;speech-based user interfaces","NIMITEK corpus;WOZ simulation;conversational agent;elicit affected speech;emotion aware spoken dialog system;emotional content;emotional corpora;genuine emotion;methodological desiderata;predetermined linguistic constraint;simulated speech based human machine interaction;substantial refinement;wizard-of-oz technique","","6","","19","","20101210","July-Dec. 2010","","IEEE","IEEE Journals & Magazines"
"EMG and visual based HMI for hands-free control of an intelligent wheelchair","L. Wei; H. Hu","School of Computer Science & Electronic Engineering, University of Essex, Wivenhoe Park, Colchester CO4 3SQ, United Kingdom","2010 8th World Congress on Intelligent Control and Automation","20100823","2010","","","1027","1032","This paper presents a new human-machine interaction (HMI) method designed for hands-free control of electric wheelchairs. Both forehead electromyography (EMG) signals and color face image information is jointly used to identify winking and jaw clenching movements. Five winking and jaw clenching movement patterns are selected and classified, mapping into five control commands to drive a simulated wheelchair in an office environment. Six subjects participated in the experiments and the result shows that this new control method can work well and reliably.","","DVD:978-1-4244-6711-2; Electronic:978-1-4244-6712-9; POD:978-1-4244-6710-5","10.1109/WCICA.2010.5554766","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5554766","Adaboost;Boosting;EMG;Eye Close Detection;Face Detection;Haar Features;SVMs;Wheelchair Controller","Electromyography;Face;Feature extraction;Humans;Muscles;Training;Wheelchairs","electric vehicles;electromyography;face recognition;human computer interaction;image classification;image colour analysis;medical image processing;wheelchairs","EMG signals;HMI;color face image information;electromyography;hands-free control;human-machine interaction;intelligent wheelchair","","4","","16","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"Reduction of complexity for the analysis of human-machine-interaction","D. Gamrad; D. Söffker","Chair of Dynamics and Control, University of Duisburg-Essen, Duisburg, Germany","2009 IEEE International Conference on Systems, Man and Cybernetics","20091204","2009","","","1263","1268","In this contribution, a concept and principal realization of an additional module within a proposed HMI analysis architecture is developed. The main aspect of this module is the reduction of complexity allowing the analysis of a Human-Machine-System. Core of the architecture is an action model, which is methodical founded on Situation-Operator-Modeling. The action model describes the interaction within a Human-Machine-System and is implemented by high-level Petri Nets. From the Petri-Net-model a state space can be generated to analyze the interaction between a human operator and the environment (in general assumed as machine). The definition of the situation representing the considered part of the real world influences the size of the state space significantly. This contribution realizes the implementation of a size-variable situation vector to reduce the complexity of the considered system. The functionality of the extended architecture is illustrated by the interaction of a human operator with an arcade game.","1062-922X;1062922X","POD:978-1-4244-2793-2","10.1109/ICSMC.2009.5345910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345910","Man-machine systems;Petri nets;State space methods","Animals;Control systems;Cybernetics;Humans;Layout;Petri nets;Psychology;State-space methods;USA Councils;Visualization","Petri nets;computer games;human computer interaction;state-space methods","HMI analysis architecture;Petri nets;arcade game;complexity reduction;human-machine-interaction;human-machine-system;situation-operator-modeling;size-variable situation vector","","2","","15","","","11-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Automatic Optimal View Selection for Natural HCI","Y. P. Guan","Sch. of Commun. & Inf. Eng., Shanghai Univ., Shanghai, China","2009 2nd International Congress on Image and Signal Processing","20091030","2009","","","1","5","Multiple cameras can be used to detect a certain object in a wide area so that users can freely move inside a wider interaction environment. One key problem is how to select the most appropriate camera with better view to perform a natural human-machine-interaction (HCI). An unsupervised scheme is developed for a best view selection. Face skin information is explicitly employed as view quality. The proposed view measurement has been defined which facilitates the system to select the most appropriate camera automatically. The proposal overcomes the effects of camera view directions and the distances between the user and the camera in selecting the best view. The approach is tested with different face databases and an actual interaction environment which shows that it is flexible and computational cost-effective. Experiments have highlighted that the mentioned method is robust and efficient when selecting the best view in a multi-camera system.","","POD:978-1-4244-4129-7","10.1109/CISP.2009.5305311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5305311","","Cameras;Computational efficiency;Databases;Face detection;Human computer interaction;Object detection;Proposals;Robustness;Skin;Testing","cameras;face recognition;man-machine systems;skin","automatic optimal view selection;face skin information;human-machine-interaction;multi-camera system;multiple cameras;view measurement;view quality","","2","","23","","","17-19 Oct. 2009","","IEEE","IEEE Conference Publications"
"Three-Dimensional Face Pose Detection and Tracking Using Monocular Videos: Tool and Application","F. Dornaika; B. Raducanu","Inst. Geographique Nat., St. Mande","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20090526","2009","39","4","935","944","Recently, we have proposed a real-time tracker that simultaneously tracks the 3D head pose and facial actions in monocular video sequences that can be provided by low quality cameras. This paper has two main contributions. First, we propose an automatic 3-D face pose initialization scheme for the real-time tracker by adopting a 2-D face detector and an eigenface system. Second, we use the proposed methods-the initialization and tracking-for enhancing the human-machine interaction functionality of an AIBO robot. More precisely, we show how the orientation of the robot's camera (or any active vision system) can be controlled through the estimation of the user's head pose. Applications based on head-pose imitation such as telepresence, virtual reality, and video games can directly exploit the proposed techniques. Experiments on real videos confirm the robustness and usefulness of the proposed methods.","1083-4419;10834419","","10.1109/TSMCB.2008.2009566","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804692","3-D head-pose estimation;AIBO robot;face detection;human–computer interaction (HCI);real-time 3-D head-pose tracking","","cameras;face recognition;human computer interaction;image sequences;mobile robots;pose estimation;robot vision;tracking;video signal processing","3D face pose detection;3D head pose estimation;AIBO robot;eigenface system;human-machine interaction functionality;monocular video sequence tracking;robot camera","Algorithms;Artificial Intelligence;Face;Humans;Image Processing, Computer-Assisted;Models, Statistical;Pattern Recognition, Automated;Posture;Principal Component Analysis;Robotics;Video Recording;Visual Fields","6","","28","","20090324","Aug. 2009","","IEEE","IEEE Journals & Magazines"
"Gesture Based English Character Recognition for Human Machine Interaction in Interactive Set Top Box Using Multi-factor Analysis","T. Chattopadhyay; P. Biswas; B. Saha; A. Pal","Convergence Solution Practices, Tata Consultancy Services Ltd., Kolkata","2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing","20090120","2008","","","134","141","In this paper authors have presented a novel approach for human machine interaction (HMI) that can be used to give alphabets as input to Internet browser in an interactive Set top box with this added facility. The device is designed with a MEMS sensor which can be worn on fingertip to send alphabetical input to an interactive set top box. Users write the English alphabet in capital letter by just using the sensor attached to their hand. Then this data is undergone some filtering and finally it is sent to the recognition module. The features used for recognition consists of chain code based and un-directional un-weighted graph based features. Each of them recognizes the input character with some confidence factor lying in the closed interval (0,1). Final decision about the recognized character is made by using multifactorial approach. We get a recognition accuracy of more than 90%. We have tested the system with the inputs given by 22 users (16 male and 6 female) each of the user is asked to write the each letter 5 times.","","CD-ROM:978-0-7695-3476-3","10.1109/ICVGIP.2008.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4756062","Gesture recognition;HMI;STB;character recognition","Character recognition;Computer graphics;Computer vision;Handicapped aids;Hidden Markov models;Humans;Internet;Keyboards;Mice;TV","character recognition;gesture recognition;graph theory;human computer interaction;interactive devices;microsensors;online front-ends","Internet browser;MEMS sensor;data filtering;data recognition;gesture-based English character recognition;human machine interaction;multifactor analysis;set top box","","4","","29","","","16-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"An investigation on Operator interface of Utility Vehicle based on Multi-discipline fusion design","Lianlian Cui; Zheng Yang","School of Urban Design, Wuhan University, Hubei, China","2008 9th International Conference on Computer-Aided Industrial Design and Conceptual Design","20081230","2008","","","124","127","Combined with the actual design of the operator interface of Utility Vehicle, this paper analyzes Interface Design in Industrial Design from various aspects. Based on the full survey and research work of the design background and the market, the essay analyses the theories of all kinds, such as shape, function, ergonomic, as well as color in the using and operation of the operator interface design with the help of interface design theory. Directed towards the specific design of operator interface of Utility Vehicle, this paper puts forward the integrated design of different subjects, which include ergonomics, color science, functional theory, psychology, and etc, making a breakthrough concerned about the traditional theory that attributing human factors to the ergonomics. Therefore, we can not only make Interface Design reflect Human-Machine performance and meet the practical requirements of HMI operation, and also expand the design factors to the psychological, spiritual areas.","","CD-ROM:978-1-4244-3291-2; POD:978-1-4244-3290-5","10.1109/CAIDCD.2008.4730534","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730534","Interface Design;Multi-discipline fusion design;Operator Interface;Utility Vehicle","Art;Color;Computer industry;Ergonomics;Man machine systems;Product design;Psychology;Shape;User interfaces;Vehicles","automobiles;human computer interaction;product design;user interfaces","car;color science;ergonomics;functional theory;human-machine interaction;industrial design;multidiscipline fusion design;psychology;utility vehicle operator interface","","0","","12","","","22-25 Nov. 2008","","IEEE","IEEE Conference Publications"
"Does multimodality really help? the classification of emotion and of On/Off-focus in multimodal dialogues - two case studies.","E. Noth; C. Hacker; A. Batliner","Lehrstuhl f&#252;r Mustererkennung, Universit&#228;t Erlangen-N&#252;rnberg, Martensstr. 3, 91058, Germany","ELMAR 2007","20080104","2007","","","9","16","Very often in articles on monomodal human-machine-interaction (HMI) it is pointed out that the results can strongly be improved if other modalities are taken into account. In this contribution we look at two different problems in HMI: the detection of emotion or user state and the question whether the user is currently interacting with the machine, himself or another person (On/Off-Focus). We present monomodal classification results for these two problems and discuss whether multimodal classification seems to be promising for the respective problem. Different fusion models are considered. The examples are taken from the German HMI projects ""SmartKom"" and ""SmartWeb"".","1334-2630;13342630","POD:978-953-7044-05-3","10.1109/ELMAR.2007.4418790","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4418790","Multimodal Human Machine Interaction","Cities and towns;Computer hacking;Displays;Graphics;Humans;Labeling;Microphones;Motion pictures;Speech synthesis;Telephony","human computer interaction;human factors","emotion detection;fusion models;monomodal classification;monomodal human-machine-interaction;multimodality","","1","","14","","","12-14 Sept. 2007","","IEEE","IEEE Conference Publications"
"HMI generation for plug-in services from semantic descriptions","A. Hildisch; J. Steurer; R. Stolle","BMW Car IT GmbH","Software Engineering for Automotive Systems, 2007. ICSE Workshops SEAS '07. Fourth International Workshop on","20070611","2007","","","4","4","We describe our implemented approach to automatically generating user interfaces (UIs) for dynamic services in the automotive domain. Dynamic services are services that are not known at design/deploy time of the HMI (human machine interaction) software of the automobile. Such services will increasingly find their way into the modern car: via mobile consumer electronics, via online servers, or via software download. In order for the driver to safely and comfortably interact with these services, their user interfaces need to be seamlessly integrated into the overall HMI system of the car and resemble the look and feel of the statically deployed HMI system. In the approach described in this paper, each service is accompanied by a description of its semantics, based on which a generic UI generator then automatically designs an appropriate UI and integrates it into the existing HMI system. We use OWL to formulate the domain-specific ontology of automotive infotainment services and OWLS to describe the service interfaces. In order to be able to express listener/notification semantics, we extended OWLS by several new constructs. Our results are based on our implementation of a UI generator for an automotive infotainment system, using the typical BMW Group HMI concepts.","","POD:0-7695-2968-2","10.1109/SEAS.2007.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4228591","","Automobiles;Automotive engineering;Concrete;Consumer electronics;Humans;OWL;Semantic Web;Software systems;User interfaces;Vehicle dynamics","automotive engineering;human computer interaction;user interfaces","HMI generation;OWLS;UI generator;automotive domain;automotive infotainment services;domain-specific ontology;dynamic services;human machine interaction;listener/notification semantics;plug-in services;semantic descriptions;user interfaces","","2","","11","","","20-26 May 2007","","IEEE","IEEE Conference Publications"
"Haptic/graphic interface for in-vehicle comfort functions - a simulator study and an experimental study","P. Bengtsson; C. Grane; J. Isaksson","Lulea Univ. of Technol., Sweden","The 2nd IEEE Internatioal Workshop on Haptic, Audio and Visual Environments and Their Applications, 2003. HAVE 2003. Proceedings.","20031110","2003","","","25","29","In today's vehicles, the human-machine interaction (HMI) is becoming increasingly complex. The number of in-vehicle comfort functions is increasing as are the number of maneuverable buttons in the vehicle. Haptic interfaces for in-vehicle functions are now commercially available. Thus, haptic interfaces are a realistic approach to an aesthetically and ergonomically improved HMI. That is, without increasing the visual load on the driver. However, as often is the case with new technologies, some haptic interfaces might have been put into operation before being studied and evaluated sufficiently, e.g. being potentially ""safety critical"". The objective of this paper is to contribute in bridging the gulf between application and research concerning implementation of haptic interfaces for in-vehicle comfort functions. Two studies are reported in the paper. Firstly, a simulator study where a haptic/graphic interface is evaluated against a traditional interface with maneuverable buttons for in-vehicle comfort functions. Secondly, an experimental study that still is in the planning phase. The study aims at investigating the interaction effects between haptic and visual feedback in a haptic/graphic interface.","","POD:0-7803-8108-4","10.1109/HAVE.2003.1244720","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1244720","","Cellular phones;Feedback;Graphics;Haptic interfaces;Interference;Man machine systems;Roads;Safety;Vehicles;Visual perception","graphical user interfaces;haptic interfaces;human computer interaction;road vehicles","graphic interface;haptic interface;human-machine interaction;in-vehicle comfort functions;maneuverable buttons;visual feedback;visual load","","5","","9","","","20-21 Sept. 2003","","IEEE","IEEE Conference Publications"
"Study on developing a computerized model of human cognitive behaviors in monitoring and diagnosing plant transients","W. Wu; H. Yoshikawa","Graduate Sch. of Energy Sci., Kyoto Univ., Japan","Systems, Man, and Cybernetics, 1998. 1998 IEEE International Conference on","20020806","1998","2","","1121","1126 vol.2","A computerized model of human cognitive behavior in monitoring and diagnosing plant transient has been developed as a part of integrated simulation system of human-machine interaction (HCI) in nuclear power plant. The general framework used of human modeling is first described, followed by the description of detailed modeling of both the monitoring and diagnosing phases. For the usability validation of the developed human modeling, computer simulation experiments have been conducted to deduce human cognitive reliability curves, by connecting the computerized model of human cognitive information processing with the dynamic simulator of nuclear power plant through man-machine interface simulator. The results of computer simulation were well agreed with those of laboratory experiments","1062-922X;1062922X","POD:0-7803-4778-1","10.1109/ICSMC.1998.727848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=727848","","Computational modeling;Computer interfaces;Computer simulation;Computerized monitoring;Human computer interaction;Joining processes;Man machine systems;Power generation;Power system modeling;Usability","computerised monitoring;digital simulation;fault diagnosis;man-machine systems;nuclear power stations;user modelling","computerized model;dynamic simulator;fault diagnosis;human cognitive behaviors;human-machine interaction;man-machine interface;monitoring;nuclear power plant;plant transient","","3","","10","","","11-14 Oct 1998","11 Oct 1998-14 Oct 1998","IEEE","IEEE Conference Publications"
"Human-computer interaction in flatness control-an intranet-based approach","G. Fodor; L. E. Mattsson; J. Mortstrand; C. Sjogren; O. Keijser; J. E. Karlsson","ABB Ind. Products, Vasteras, Sweden","Systems, Man, and Cybernetics, 1998. 1998 IEEE International Conference on","20020806","1998","2","","1323","1328 vol.2","Intranet information servers are increasingly used for human-machine interaction (HMI) in real-time control applications. As compared to office-based applications, industrial HMI servers give rise to specific questions regarding the compatibility of the intranet architecture with the traditional real-time architecture and services. This paper presents results following practical experience with an intranet HMI interface used for flatness control systems in cold rolling mills. Different aspects of the design approach are illustrated by a working system. The key result reported in the paper is that real-time intranet-based HMI approaches must consider certain constraints for the overall architecture of the control system. The properties of this architecture are described and evaluated practically","1062-922X;1062922X","POD:0-7803-4778-1","10.1109/ICSMC.1998.728066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=728066","","Access protocols;Actuators;Automatic control;Control systems;Electrical equipment industry;Error correction;Milling machines;Stress measurement;Strips;Transducers","control system synthesis;interactive systems;intranets;process control;real-time systems;rolling mills;search engines;spatial variables control;user interfaces","cold rolling mills;control system architecture constraints;control systems design;flatness control;human-machine interaction;industrial servers;intranet architecture compatibility;intranet information servers;real-time architecture;real-time control;real-time services;user interface","","1","","3","","","11-14 Oct 1998","11 Oct 1998-14 Oct 1998","IEEE","IEEE Conference Publications"
